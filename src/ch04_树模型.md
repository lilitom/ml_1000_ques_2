# 4 树模型
  [TOC]
  
## 4.1 基础树

  
### 4.1.1 为什么C4.5能处理连续特征而ID3不行？

  这是因为ID3在设计的时候根本就没考虑过要处理连续特征，所以它自然就不能处理连续特征。那为什么ID3不考虑连续特征？这是因为任何研究都是循循渐进的，每一个研究只会将精力放在当前最重要的研究点之上。ID3与C4.5都是Quinlan 的作品，而ID3的研究重点是如何设计高效的节点分裂方法来生长决策树，因此它并不太在意如何去处理连续特征。为此，ID3提出了使用信息增益来衡量一次节点分裂的优劣，它是第一个成功将信息论相关理论使用到决策树算法中的，从这点来看它的时代意义比较重要。因此从学术贡献来看，它确实也没有必要再去处理一些琐碎而简单的问题了。而C4.5的重点则是将ID3的成果工程化，让决策树能真正解决实际中的复杂问题，所以C4.5设计了详细的连续特征处理方法和剪枝算法。以现在的眼光来看，只要你愿意，可以很容易地将ID3改造为有能力处理连续特征的决策树。
  
### 4.1.2 剪枝的策略是啥?

  在决策树算法中，为了尽可能正确分类训练样本， 节点划分过程不断重复， 有时候会造成决策树分支过多，以至于将训练样本集自身特点当作泛化特点， 而导致过拟合。因此可以采用剪枝处理来去掉一些分支来降低过拟合的风险。
    剪枝的基本策略有预剪枝（pre-pruning）和后剪枝（post-pruning）。
    预剪枝：在决策树生成过程中，在每个节点划分前先估计其划分后的泛化性能， 如果不能提升，则停止划分，将当前节点标记为叶结点。
    后剪枝：生成决策树以后，再自下而上对非叶结点进行考察， 若将此节点标记为叶结点可以带来泛化性能提升，则修改之。
  
### 4.1.3 树模型one_hot有哪些问题？

  one-hot coding是类别特征的一种通用解决方法，然而在树模型里面，这并不是一个比较好的方案，尤其当类别特征维度很高的时候。主要的问题是：
    1.可能无法在这个类别特征上进行切分。使用one-hot coding的话，意味着在每一个决策节点上只能用 one-vs-rest (例如是不是狗，是不是猫，等等) 的切分方式。当特征纬度高时，每个类别上的数据都会比较少，这时候产生的切分不平衡，切分增益（split gain）也会很小（比较直观的理解是，不平衡的切分和不切分几乎没有区别）。  
  2.会影响决策树的学习。因为就算可以在这个类别特征进行切分，也会把数据切分到很多零散的小空间上，如图1左所示。而决策树学习时利用的是统计信息，在这些数据量小的空间上，统计信息不准确，学习会变差。但如果使用图1右边的切分方法，数据会被切分到两个比较大的空间，进一步的学习也会更好。
  ![img](https://img-blog.csdnimg.cn/41dd460bbcd146abb0fbba9916d8d49f.png)
    
### 4.1.4 如何解决树模型中one_hot的问题?

  1.类别特征的最优切分。这个方法需要对应工具的支持，我所知的支持这个方法的工具有h2o.gbm和LightGBM,用LightGBM可以直接输入类别特征，并产生同图1右边的最优切分。在一个k维的类别特征寻找最优切分，朴素的枚举算法的复杂度是指数的 O(2^k)。LightGBM 用了一个 O(klogk)[1] 的算法。算法流程如图2所示：在枚举分割点之前，先把直方图按照每个类别对应的label均值进行排序；然后按照排序的结果依次枚举最优分割点。当然，这个方法很容易过拟合，所以LightGBM里面还增加了很多对于这个方法的约束和正则化。图3是一个简单的对比实验，可以看到Optimal的切分方法在AUC提高了1.5个点，并且时间只多了20% 。 
    2.转成数值特征。在使用 sklearn 或 XGBoost 等不支持类别特征的最优切分工具时，可以用这个方法。常见的转换方法有: a) 把类别特征转成one-hot coding扔到NN里训练个embedding；b) 类似于CTR特征，统计每个类别对应的label(训练目标)的均值。统计的时候有一些小技巧，比如不把自身的label算进去(leave-me-out, leave-one-out)统计， 防止信息泄露。  
    3.其他的编码方法，比如binary coding等等，同样可以用于不支持类别特征的算法。这里有一个比较好的开源项目，封装了常见的各种编码方法: https://github.com/scikit-learn-contrib/category_encoders
    
### 4.1.5 为啥决策树后剪枝比预剪枝要好？

  - 预剪枝  
  预剪枝使得决策树的很多分支没有展开，也就是没有一步一步计算然后分裂下去了，这不仅降低了过拟合的风险，还显著减少了树模型的训练时间开销。但是另一方面，有些分支的当前划分虽不能提升泛化性能、甚至可能导致泛化性能暂时下降，但是在其基础上进行的后续划分有可能导致性能显著提升(但是我们简单嘛，就不继续划分了)。预剪枝基于贪心本质，抱着能多剪就多剪枝从而招来欠拟合的风险。采用这种方法得到的决策树可能就是如下这种：  
  ![image](https://img-blog.csdnimg.cn/984eef32683a46c389f6e824772773eb.png)  
  可以看到在这棵树比价简单，泛化性能比较好，也不会过拟合，但是就是太太简单了，会导致预测的时候偏差较大，也是我们说的欠拟合。
    - 后剪枝  
  在决策树生成后进行剪枝，这也符合我们做事的逻辑和条理。后剪枝决策树通常比预剪枝决策树保留了更多的分支(所以说计算开销还是比较大滴)。一般情况下，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。所以剪枝后的树大概就是你看到的下面的这个样子：
  ![image](https://img-blog.csdnimg.cn/d263dde49a5b40cab90c86f11297ed08.png)
    
### 4.1.6 决策树中有哪些剪枝算法

  决策树中常见的剪枝算法有：  
  Reduced-Error Pruning（REP,错误率降低剪枝）  
  Pesimistic-Error Pruning（PEP,悲观错误剪枝）  
  Cost-Complexity Pruning（CCP，代价复杂度剪枝）  
  Minimum Error Pruning （MEP, 最小误差剪枝）  
    REP：通过一个新的验证集来纠正树的过拟合问题。对于决策树中的每一个非叶子节点的子树，我们将它替换成一个叶子节点，该叶子节点的类别用大多数原则来确定，这样就产生了一个新的相对简化决策树，然后比较这两个决策树在验证集中的表现。如果新的决策树在验证集中的正确率较高，那么该子树就可以替换成叶子节点，从而达到决策树剪枝的目的。
    PEP：这个算法和REP差不多，和REP不同之处在于：PEP不需要新的验证集，并且PEP是自上而下剪枝的。由于我们还是用生成决策树时相同的训练样本，那么对于每个节点剪枝后的错分率一定是会上升的，因此在计算错分率时需要加一个惩罚因子0.5。
    CPC：CCP算法为子树$T_i$定义了代价和复杂度，以及一个衡量代价与复杂度之间关系的参数$\alpha$。代价指的是在剪枝过程中因子树$T_i$被叶节点替代而增加的错分样本;复杂度表示剪枝后子树$T_i$减少的叶结点数; 从下到上计算每一个非叶节点的$\alpha$值，然后每一次都剪掉具有最小值的子树${T_0}{T_1} \cdots {T_n}$，最后得到,其中是$T_0$完整的数，$T_n$表示根节点，然后根据真实的错误率在${T_0}{T_1} \cdots {T_n}$中选择一个最好的。
    MEP：此方法的基本思路是采用自底向上的方式，对于树中每个非叶节点。首先计算该节点的误差,然后，计算该节点每个分支的误差,并且加权相加，权为每个分支拥有的训练样本比例。如果大于,则保留该子树；否则就剪裁。
    ![img](https://img-blog.csdnimg.cn/373937826586452cad330f80876e589a.png)
  详细的结果如上图所示
    
## 4.2 提升树

  
### 4.2.1 为什么GBDT的树深度较RF通常都比较浅？

  对于机器学习来说，泛化误差可以理解为两部分，分别是偏差（bias）和方差（variance）；偏差指的是算法的期望预测与真实预测之间的偏差程度，反应了模型本身的拟合能力；方差度量了同等大小的训练集的变动导致学习性能的变化，刻画了数据扰动所导致的影响。当模型越复杂时，拟合的程度就越高，模型的训练偏差就越小；但此时如果换一组数据可能模型的变化就会很大，即模型的方差很大，所以模型过于复杂的时候会导致过拟合。
    对于RF来说由于并行训练很多不同的分类器的目的就是降低这个方差（variance）。所以对于每个基分类器来说，目标就是如何降低这个偏差（bias），所以我们会采用深度很深甚至不剪枝的决策树。而对于GBDT来说由于利用的是残差逼近的方式，即在上一轮的基础上更加拟合原数据，所以可以保证偏差（bias），所以对于每个基分类器来说，问题就在于如何选择 variance 更小的分类器，即更简单的分类器，所以我们选择了深度很浅的决策树。
    
### 4.2.2 GBDT为什么使用cart回归树而不是使用分类树?

  GBDT主要是利用残差逼近的方式，这就意味每棵树的值是连续的可叠加的，这一点和回归树输出连续值不谋而合，如果采用分类树，那么残差逼近进行叠加就会使得这种叠加没有意义，比如男+男+女=到底是男是女。这个是GBDT基本原理决定的。
    
### 4.2.3 GBDT哪些部分可以并行？

  1、计算每个样本的负梯度；
  2、分裂挑选最佳特征及其分割点时，对特征计算相应的误差及均值时；
  3、更新每个样本的负梯度时；
  4、最后预测过程中，每个样本将之前的所有树的结果累加的时候。
    
### 4.2.4 GBDT与RF的区别？

  相同点： 
  1、GBDT与RF都是采用多棵树组合作为最终结果；这是两者共同点。 
  不同点： 
  1、RF的树可以是回归树也可以是分类树，而GBDT只能是回归树。 
  2、RF中树是独立的，相互之间不影响，可以并行；而GBDT树之间有依赖，是串行。 
  3、RF最终的结果是有多棵树表决决定，而GBDT是有多棵树叠加组合最终的结果。 
  4、RF对异常值不敏感，原因是多棵树表决，而GBDT对异常值比较敏感，原因是当前的错误会延续给下一棵树。 
  5、RF是通过减少模型的方差来提高性能，而GBDT是减少模型的偏差来提高性能的。
    
### 4.2.5 简单介绍一下XGBoost
  首先需要说一说GBDT，它是一种基于boosting增强策略的加法模型，训练的时候采用前向分布算法进行贪婪的学习，每次迭代都学习一棵CART树来拟合之前 t-1 棵树的预测结果与训练样本真实值的残差。  
  XGBoost对GBDT进行了一系列优化，比如损失函数进行了二阶泰勒展开、目标函数加入正则项、支持并行和默认缺失值处理等，在可扩展性和训练速度上有了巨大的提升，但其核心思想没有大的变化。
  参考：  
  https://zhuanlan.zhihu.com/p/83901304 
    
### 4.2.6 树模型怎么查看特征重要性

  1. 通过OOB  
  OOB的具体介绍可以看我之前的专栏https://zhuanlan.zhihu.com/p/77473961
  那么OOB是怎么做到可以对特征重要性进行排序的呢，先用训练好的模型对OOB数据进行打分，计算出AUC或其他业务定义的评估指标；接着对OOB数据中的每个特征：(1) 随机shuffle当前特征的取值；(2) 重新对当前数据进行打分，计算评估指标；(3)计算指标变化率。按照上面方式，对每个特征都会得到一个变化率，最后按照变化率排序来量化特征重要性。  
  2. 通过Gini  
  说白了就是看看每个特征在随机森林中的每颗树上做了多大的贡献，然后取个平均值，最后比一比特征之间的贡献大小。对于生成的每棵树，计算每个分裂节点的Gini指数,特征 Xj 在节点m的重要性可以通过分裂前后的特征 GIm 的差值来表示。
    
### 4.2.7 随机森林需要交叉验证吗？

  随机森林是不需要的，它属于bagging集成算法，采用Bootstrap，理论和实践可以发现Bootstrap每次约有1/3的样本不会出现在Bootstrap所采集的样本集合中。故没有参加决策树的建立，这些数据称为袋外数据oob，歪点子来了，这些袋外数据可以用于取代测试集误差估计方法，可用于模型的验证。
    
### 4.2.8 XGBoost与GBDT的联系和区别有哪些？

  （1）GBDT是机器学习算法，XGBoost是该算法的工程实现。  
  （2）正则项：在使用CART作为基分类器时，XGBoost显式地加入了正则项来控制模型的复杂度，有利于防止过拟合，从而提高模型的泛化能力。  
  （3）导数信息：GBDT在模型训练时只使用了代价函数的一阶导数信息，XGBoost对代价函数进行二阶泰勒展开，可以同时使用一阶和二阶导数。  
  （4）基分类器：传统的GBDT采用CART作为基分类器，XGBoost支持多种类型的基分类器，比如线性分类器。  
  （5）子采样：传统的GBDT在每轮迭代时使用全部的数据，XGBoost则采用了与随机森林相似的策略，支持对数据进行采样。  
  （6）缺失值处理：传统GBDT没有设计对缺失值进行处理，XGBoost能够自动学习出缺失值的处理策略。  
  （7）并行化：传统GBDT没有进行并行化设计，注意不是tree维度的并行，而是特征维度的并行。XGBoost预先将每个特征按特征值排好序，存储为块结构，分裂结点时可以采用多线程并行查找每个特征的最佳分割点，极大提升训练速度。  
    
### 4.2.9 为什么XGBoost泰勒二阶展开后效果就比较好呢？

  - 从为什么会想到引入泰勒二阶的角度来说（可扩展性）：XGBoost官网上有说，当目标函数是MSE时，展开是一阶项（残差）+二阶项的形式，而其它目标函数，如logistic loss的展开式就没有这样的形式。为了能有个统一的形式，所以采用泰勒展开来得到二阶项，这样就能把MSE推导的那套直接复用到其它自定义损失函数上。简短来说，就是为了统一损失函数求导的形式以支持自定义损失函数。至于为什么要在形式上与MSE统一？是因为MSE是最普遍且常用的损失函数，而且求导最容易，求导后的形式也十分简单。所以理论上只要损失函数形式与MSE统一了，那就只用推导MSE就好了。
  - 从二阶导本身的性质，也就是从为什么要用泰勒二阶展开的角度来说（精准性）：二阶信息本身就能让梯度收敛更快更准确。这一点在优化算法里的牛顿法中已经证实。可以简单认为一阶导指引梯度方向，二阶导指引梯度方向如何变化。简单来说，相对于GBDT的一阶泰勒展开，XGBoost采用二阶泰勒展开，可以更为精准的逼近真实的损失函数。  
    详细可以看 https://www.zhihu.com/question/277638585/answer/522272201
    
### 4.2.10 XGBoost对缺失值是怎么处理的？

  在普通的GBDT策略中，对于缺失值的方法是先手动对缺失值进行填充，然后当做有值的特征进行处理，但是这样人工填充不一定准确，而且没有什么理论依据。
    - 在特征k上寻找最佳 split point 时，不会对该列特征 missing 的样本进行遍历，而只对该列特征值为 non-missing 的样本上对应的特征值进行遍历，通过这个技巧来减少了为稀疏离散特征寻找 split point 的时间开销。
      - 在逻辑实现上，为了保证完备性，会将该特征值missing的样本分别分配到左叶子结点和右叶子结点，两种情形都计算一遍后，选择分裂后增益最大的那个方向（左分支或是右分支），作为预测时特征值缺失样本的默认分支方向。
      - 如果在训练中没有缺失值而在预测中出现缺失，那么会自动将缺失值的划分方向放到右子结点。
    
### 4.2.11 XGBoost为什么快

  - 分块并行：训练前每个特征按特征值进行排序并存储为Block结构，后面查找特征分割点时重复使用，并且支持并行查找每个特征的分割点
    - 候选分位点：每个特征采用常数个分位点作为候选分割点
    - CPU cache 命中优化： 使用缓存预取的方法，对每个线程分配一个连续的buffer，读取每个block中样本的梯度信息并存入连续的Buffer中。
    - Block 处理优化：Block预先放入内存；Block按列进行解压缩；将Block划分到不同硬盘来提高吞吐
    
### 4.2.12 XGBoost防止过拟合的方法

  XGBoost在设计时，为了防止过拟合做了很多优化，具体如下：  
  - 目标函数添加正则项：叶子节点个数+叶子节点权重的L2正则化  
  - 列抽样：训练的时候只用一部分特征（不考虑剩余的block块即可）  
  - 子采样：每轮计算可以不使用全部样本，使算法更加保守  
  - shrinkage: 可以叫学习率或步长，为了给后面的训练留出更多的学习空间  
    
### 4.2.13 XGBoost为什么若模型决策树的叶子节点值越大，越容易过拟合呢？

  xgb最终的决策就是wx,如果某个w太大，则显然w对应叶子结点对最终的输出起到绝大部分的贡献，那么如果第一个叶子结点对应的基树拟合的过头，很容易导致整体的输出方差增大引发过拟合。更小的w表示更小的模型复杂度，因此来说w小点是好的。
    详细见  
  https://www.zhihu.com/question/359567100  https://blog.csdn.net/weixin_37933986/article/details/69681671
      
### 4.2.14 XGBoost为什么可以并行训练？

  - XGBoost的并行，并不是说每棵树可以并行训练，XGBoost本质上仍然采用boosting思想，每棵树训练前需要等前面的树训练完成才能开始训练。  
  - XGBoost的并行，指的是特征维度的并行：在训练之前，每个特征按特征值对样本进行预排序，并存储为Block结构，在后面查找特征分割点时可以重复使用，而且特征已经被存储为一个个block结构，那么在寻找每个特征的最佳分割点时，可以利用多线程对每个block并行计算。
    
### 4.2.15 XGBoost中叶子结点的权重如何计算出来

  利用一元二次函数求最值的知识，当目标函数达到最小值Obj*时，每个叶子结点的权重为wj*。
  ```math
  w_j^* = -G_j/(H_j+\lambda)
  ```
    
### 4.2.16 XGBoost中的一棵树的停止生长条件

  - 当新引入的一次分裂所带来的增益Gain<0时，放弃当前的分裂。这是训练损失和模型结构复杂度的博弈过程。
    - 当树达到最大深度时，停止建树，因为树的深度太深容易出现过拟合，这里需要设置一个超参数max_depth。
    - 当引入一次分裂后，重新计算新生成的左、右两个叶子结点的样本权重和。如果任一个叶子结点的样本权重低于某一个阈值，也会放弃此次分裂。这涉及到一个超参数:最小样本权重和，是指如果一个叶子节点包含的样本数量太少也会放弃分裂，防止树分的太细。
    
### 4.2.17 Xboost中的min_child_weight是什么意思

  一般来说，我们定义的不带正则项的损失函数是这个
  ```math
  \frac{1}{2} (y_i-\hat y_i^2)
  ```
  那么hi=1，Hj即叶子节点上的样本数，min_child_weight就是叶子上的最小样本数，不最小样本总数啊，只是在这个情况下是。
    
### 4.2.18 Xgboost中的gamma是什么意思

  指的是叶节点需要分裂需要的最小损失减少量，也就是![image](https://img-blog.csdn.net/20180819171358821?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI0NTE5Njc3/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)公式中的r。
    详细见  
  https://www.zhihu.com/question/68621766/answer/336096221
    
### 4.2.19 Xgboost中的参数

  具体见 https://blog.csdn.net/han_xiaoyang/article/details/52665396
    
### 4.2.20 RF和GBDT的区别

    相同点：
    - 都是由多棵树组成，最终的结果都是由多棵树一起决定。
    不同点：
    - 集成学习：RF属于bagging思想，而GBDT是boosting思想
  - 偏差-方差权衡：RF不断的降低模型的方差，而GBDT不断的降低模型的偏差
  训练样本：RF每次迭代的样本是从全部训练集中有放回抽样形成的，而GBDT每次使用全部样本
  - 并行性：RF的树可以并行生成，而GBDT只能顺序生成(需要等上一棵树完全生成)
  - 最终结果：RF最终是多棵树进行多数表决（回归问题是取平均），而GBDT是加权融合
  - 数据敏感性：RF对异常值不敏感，而GBDT对异常值比较敏感
  - 泛化能力：RF不易过拟合，而GBDT容易过拟合
    
### 4.2.21 xgboost本质上是树模型，能进行线性回归拟合么

  Xgboost中可以使用的，gbliner这个参数，那么它就使用线性基学习器来进行学习了。
    
### 4.2.22 Xgboos是如何调参的

  一般来说主要调节的几个参数有如下
  - max_depth
  - learning_rate
  - n_estimators
  - min_child_weight
  - subsample
  - colsample_bytree
    XGBoost的作者把所有的参数分成了三类：  
  1、通用参数：宏观函数控制。  
  2、Booster参数：控制每一步的booster(tree/regression)。  
  3、学习目标参数：控制训练目标的表现。  
    调参主要由一下步骤
  1. 确定数据的的情况，设置好相应的参数
  2. 调参方法1：
  1. 选择较高的学习速率(learning rate)。一般情况下，学习速率的值为0.1。但是，对于不同的问题，理想的学习速率有时候会在0.05到0.3之间波动。选择对应于此学习速率的理想决策树数量。XGBoost有一个很有用的函数“cv”，这个函数可以在每一次迭代中使用交叉验证，并返回理想的决策树数量。
  2.  对于给定的学习速率和决策树数量，进行决策树特定参数调优(max_depth, min_child_weight, gamma, subsample, colsample_bytree)。在确定一棵树的过程中，我们可以选择不同的参数，待会儿我会举例说明。
  3.  xgboost的正则化参数的调优。(lambda, alpha)。这些参数可以降低模型的复杂度，从而提高模型的表现。4. 降低学习速率，确定理想参数。
  3. 调参方法2：  
  使用网格搜索
  4. 调参方法3：  
  使用随机搜索
  5. 调参方法4：  
  使用贝叶斯调参方法
  详细见  
  https://zhuanlan.zhihu.com/p/29649128
    
### 4.2.23 为什么xgboost/gbdt在调参时为什么树的深度很少就能达到很高的精度？

  Boosting主要关注降低偏差，因此Boosting能基于泛化性能相当弱的学习器构建出很强的集成；Bagging主要关注降低方差，因此它在不剪枝的决策树、神经网络等学习器上效用更为明显。
    gbdt属于boosting的方法，其主要关注的是减少偏差，多棵树进行叠加后可以保证较高的精度。
    
### 4.2.24 为什么常规的gbdt和xgboost不适用于类别特别多的特征?

  one-hot coding是类别特征的一种通用解决方法，然而在树模型里面，这并不是一个比较好的方案，尤其当类别特征维度很高的时候。主要的问题是：  
  - 可能无法在这个类别特征上进行切分  
  使用one-hot coding的话，意味着在每一个决策节点上只能用 one-vs-rest (例如是不是狗，是不是猫，等等) 的切分方式。当特征纬度高时，每个类别上的数据都会比较少，这时候产生的切分不平衡，切分增益（split gain）也会很小（比较直观的理解是，不平衡的切分和不切分几乎没有区别）。
  - 会影响决策树的学习  
  因为就算可以在这个类别特征进行切分，也会把数据切分到很多零散的小空间上，如图1左所示。而决策树学习时利用的是统计信息，在这些数据量小的空间上，统计信息不准确，学习会变差。但如果使用图1右边的切分方法，数据会被切分到两个比较大的空间，进一步的学习也会更好。
  ![image](https://pic2.zhimg.com/80/v2-17fc885c67ae576937533c7bda71a83f_720w.jpg?source=1940ef5c)
    
### 4.2.25 怎么处理类别特征在树模型下？

  - 可以使用lightGBM模型
  - 可以用embedding
  - 其他的编码方法，比如binary coding
    详细见  
  https://www.zhihu.com/question/266195966
    
### 4.2.26 GBDT的预测结果有负数，为啥？

  这里不是严格意义上说GBDT的预测结果一定为负数，而指的是训练集的结果中GBDT拟合的label都为正数，而在测试集中却出现了负数的情况。  
  是可能会出现负值的，出现的情况原因可能有如下：
  如果在loss函数中没有加对负数输出的惩罚项（regularization），就有可能得到负数输出。
  首先要看得到负数的的输入值是否在training data中出现过，如果没出现过，并且这种数据点很少，可以认为这些是outlier。也可以把负数变为0。
  training data里很多输出接近于0，testing里出现一些接近于0的负数也很正常。
  样本较少，特征较少的情况可能会出现，因为GBDT是加法模型，然后下一轮都是上一轮预测值和实际值的残差作为label继续拟合，最后将结果相加，这样最后可能会出现负值。
  我说个比较简单的理解思路，GBDT你拟合的是残差，这个残差可正可负，第一棵树得到的预测值偏大，那么后续拟合的就是负值，如果拟合的不好，多棵树相加的结果还是一个负数(越界的数)。
          
### 4.2.27 参考

  > https://zhuanlan.zhihu.com/p/65597945
    